{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "6. Describe the class of strings matched by the following regular expressions.\n",
        "\n",
        "[a-zA-Z]+ : 대소문자 중 하나 이상의 문자를 포함한 단어\n",
        "\n",
        "[A-Z][a-z]* : 하나의 대문자 뒤에 소문자가 0개 이상 있는 단어\n",
        "\n",
        "p[aeiou]{,2}t : p로 시작해서 t로 끝나고 그 사이에 모음이 0~2개 있는 단어\n",
        "\n",
        "\\d+(\\.\\d+)? : 실수(정수 혹은 소수)\n",
        "\n",
        "([^aeiou][aeiou][^aeiou])* : [모음이 아닌 것, 모음, 모음이 아닌 것] 구조의 문자열 0회 이상 반복\n",
        "\n",
        "\\w+|[^\\w\\s]+ : 하나 이상의 숫자나 대문자나 소문자가 있거나, 숫자나 대문자나 소문자나 white space를 어떤 것도 포함하지 않는 하나 이상의 문자열\n",
        "\n",
        "Test your answers using nltk.re_show()."
      ],
      "metadata": {
        "id": "2z6xgIcIOl3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, re\n",
        "text = \"Text messaging, or texting, is the act of composing and sending brief, electronic messages between two or more mobile phones, or fixed or portable devices over a phone network.\""
      ],
      "metadata": {
        "id": "1YVYF7tIWGJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'[a-zA-Z]+',text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrTBCbuqRHim",
        "outputId": "4c2bf1b3-6024-493f-8b8c-a03315c0b361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Text} {messaging}, {or} {texting}, {is} {the} {act} {of} {composing} {and} {sending} {brief}, {electronic} {messages} {between} {two} {or} {more} {mobile} {phones}, {or} {fixed} {or} {portable} {devices} {over} {a} {phone} {network}.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'[A-Z][a-z]*',text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbnnXWMjRILU",
        "outputId": "887bbb27-0d56-4a71-8770-aeb610ca8907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Text} messaging, or texting, is the act of composing and sending brief, electronic messages between two or more mobile phones, or fixed or portable devices over a phone network.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'p[aeiou]{,2}t','pet pt peet piiit text act is')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l6rLMCORKWV",
        "outputId": "7a3a3edf-cc9a-4f55-b40e-9a6a399f6462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{pet} {pt} {peet} piiit text act is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'\\d+(\\.\\d+)?','text me is or message 23 1.09 -9.91 1,2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VJuK8M8RQzc",
        "outputId": "699beaec-c980-45dd-b6bb-c6c34007d47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text me is or message {23} {1.09} -{9.91} {1},{2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ1E8SPGRSUx",
        "outputId": "7602e7a9-f614-43d9-b614-073abee18226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Tex}{}t{} {messag}{}i{}n{}g{},{ or}{} {textin}{}g{},{ is}{} {}t{he }{}a{}c{}t{ of}{} {compos}{}i{}n{}g{ an}{}d{} {sendin}{}g{} {}b{}r{}i{}e{}f{},{ el}{}e{}c{}t{ron}{}i{}c{} {messag}{}e{}s{} {bet}{}w{}e{}e{}n{} {}t{wo }{}o{}r{} {mor}{}e{} {mob}{}i{le }{}p{hon}{}e{}s{},{ or}{} {fix}{}e{}d{ or}{} {portable dev}{}i{ces ov}{}e{}r{ a }{}p{hon}{}e{} {networ}{}k{}.{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.re_show(r'\\w+|[^\\w\\s]+', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfv3hkh0RUiB",
        "outputId": "ab19b27e-8e9a-432e-9d46-3800a8916c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Text} {messaging}{,} {or} {texting}{,} {is} {the} {act} {of} {composing} {and} {sending} {brief}{,} {electronic} {messages} {between} {two} {or} {more} {mobile} {phones}{,} {or} {fixed} {or} {portable} {devices} {over} {a} {phone} {network}{.}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a function unknown() that takes a URL as its argument, and returns a list of unknown words that occur on that webpage. In order to do this, extract all substrings consisting of lowercase letters (using re.findall()) and remove any items from this set that occur in the Words Corpus (nltk.corpus.words). Try to categorize these words manually and discuss your findings.\n",
        "\n",
        "파생어, 줄임말 등 nltk의 words corpus에 있지 않은 단어들을 뽑아내는 함수이다."
      ],
      "metadata": {
        "id": "g_TdwU0GOsNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('words')\n",
        "from urllib import request\n",
        "\n",
        "def unknown(url):\n",
        "    html = request.urlopen(url).read().decode('utf8')\n",
        "    lowers = re.findall(r'\\b[a-z]+', html)\n",
        "    words = nltk.corpus.words.words()\n",
        "    unknowns = [w for w in lowers if w not in words]\n",
        "    return unknowns\n",
        "\n",
        "print(unknown('https://en.wikipedia.org')[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzaXD6pgYhOC",
        "outputId": "64009b2c-9b6a-4bcf-da55-254ca4555d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['html', 'html', 'nojs', 'lang', 'dir', 'ltr', 'charset', 'js', 'wg', 'wg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Use the Porter Stemmer to normalize some tokenized text, calling the stemmer on each word. Do the same thing with the Lancaster Stemmer and see if you observe any differences."
      ],
      "metadata": {
        "id": "9PMD3hyMOvYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "text = \"Text messaging, or texting, is the act of composing and sending brief, electronic messages between two or more mobile phones, or fixed or portable devices over a phone network.\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "porter_output = [nltk.PorterStemmer().stem(t) for t in tokens]             \n",
        "lancaster_output = [nltk.LancasterStemmer().stem(t) for t in tokens]"
      ],
      "metadata": {
        "id": "aGfwfV-mWDOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce56a7b-784a-419c-f0bc-3dfe4110018d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in zip(porter_output, lancaster_output):\n",
        "    if x != y:\n",
        "        print(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3yycC2NayVQ",
        "outputId": "ee1feb90-84f4-479b-f226-a212d5648439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messag mess\n",
            "messag mess\n",
            "more mor\n",
            "mobil mobl\n",
            "phone phon\n",
            "portabl port\n",
            "devic dev\n",
            "over ov\n",
            "phone phon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Write programs to process the Brown Corpus and find answers to the following questions:"
      ],
      "metadata": {
        "id": "S2yih3CaO0-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "\n",
        "brown_tagged = brown.tagged_words()\n",
        "cfd = nltk.ConditionalFreqDist(brown_tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzgIg1sGgoje",
        "outputId": "48d00aad-4605-4b0a-f3e1-c865496cf0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the -s suffix.)"
      ],
      "metadata": {
        "id": "rERUnYsHg3wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plural = set()\n",
        "for word in set(brown.words()):\n",
        "    if cfd[word+'s']['NNS'] > cfd[word]['NN']:\n",
        "        plural.add(word)\n",
        "\n",
        "list(plural)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPXG-rcOg1MO",
        "outputId": "c7790756-7ed9-413c-ad56-c0b3658e8502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['song',\n",
              " 'chromatic',\n",
              " 'particle',\n",
              " 'Survey',\n",
              " 'progression',\n",
              " 'representative',\n",
              " 'gassing',\n",
              " 'thank',\n",
              " 'Traveler',\n",
              " 'hostage']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Which word has the greatest number of distinct tags. What are they, and what do they represent?"
      ],
      "metadata": {
        "id": "wVklbdrIg65w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tag_dict = {k:len(cfd[k]) for k in cfd}\n",
        "greatest = max(tag_dict, key=lambda key: tag_dict[key])\n",
        "greatest, cfd[greatest].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hWx0U1miM9P",
        "outputId": "5e9ed040-f86b-475d-8d39-95c9293c1fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('that',\n",
              " dict_keys(['CS', 'WPS', 'DT', 'QL', 'WPO', 'CS-HL', 'DT-NC', 'NIL', 'WPS-NC', 'WPO-NC', 'CS-NC', 'WPS-HL']))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) List tags in order of decreasing frequency. What do the 20 most frequent tags represent?"
      ],
      "metadata": {
        "id": "TQy1e485g9AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.FreqDist([t for (_, t) in brown_tagged]).most_common(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeTmOphdjVVx",
        "outputId": "f2a9b357-66eb-4a15-aa9f-738b66859db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NN', 152470),\n",
              " ('IN', 120557),\n",
              " ('AT', 97959),\n",
              " ('JJ', 64028),\n",
              " ('.', 60638),\n",
              " (',', 58156),\n",
              " ('NNS', 55110),\n",
              " ('CC', 37718),\n",
              " ('RB', 36464),\n",
              " ('NP', 34476),\n",
              " ('VB', 33693),\n",
              " ('VBN', 29186),\n",
              " ('VBD', 26167),\n",
              " ('CS', 22143),\n",
              " ('PPS', 18253),\n",
              " ('VBG', 17893),\n",
              " ('PP$', 16872),\n",
              " ('TO', 14918),\n",
              " ('PPSS', 13802),\n",
              " ('CD', 13510)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Which tags are nouns most commonly found after? What do these tags represent?\n",
        "\n",
        "전치사 또는 종속 접속사"
      ],
      "metadata": {
        "id": "8sBh3G9lg-pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noun_after = [b[1] for (a, b) in nltk.bigrams(brown_tagged) if a[1].startswith('NN')]\n",
        "fdist = nltk.FreqDist(noun_after)\n",
        "[tag for (tag, _) in fdist.most_common(1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkDZecGPlq8E",
        "outputId": "f8f78001-9f4f-4bb9-ed45-65c934bb7705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IN']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write code to search the Brown Corpus for particular words and phrases according to tags, to answer the following questions:"
      ],
      "metadata": {
        "id": "OI_UnSl9PEu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "\n",
        "text = brown.words()\n",
        "set_text = set(text)\n",
        "brown_tagged = brown.tagged_words()\n",
        "cfd = nltk.ConditionalFreqDist(brown_tagged)\n",
        "conditions = cfd.conditions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE3qr1Spn4O8",
        "outputId": "62f6d619-1238-4637-f179-9531ab92172a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Produce an alphabetically sorted list of the distinct words tagged as MD."
      ],
      "metadata": {
        "id": "gWP5dS9KnAk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "md_words = [condition for condition in conditions if cfd[condition]['MD'] != 0]\n",
        "md_words.sort()\n",
        "print(md_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O42MvmrhoSl7",
        "outputId": "c22b2f82-6e04-492a-a9ff-d103dbd39d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Can', 'Could', 'May', 'Might', 'Must', 'Ought', 'Shall', 'Should', 'Will', 'Would', \"c'n\", 'can', 'colde', 'could', 'dare', 'kin', 'maht', 'mai', 'may', 'maye', 'mayst', 'might', 'must', 'need', 'ought', 'shall', 'should', 'shuld', 'shulde', 'wil', 'will', 'wilt', 'wod', 'wold', 'wolde', 'would']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Identify words that can be plural nouns or third person singular verbs (e.g. deals, flies)."
      ],
      "metadata": {
        "id": "L5eRD49knCyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "two_words = [condition for condition in conditions if cfd[condition]['NNS'] and cfd[condition]['VBZ']]\n",
        "two_words.sort()\n",
        "print(two_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJ9DA1cpPQk",
        "outputId": "a14e128f-0aff-4571-854f-ff0b22824695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aids', 'Designs', 'Increases', 'Makes', 'Reports', 'Says', 'accounts', 'acts', 'addresses', 'advances', 'affects', 'aids', 'aims', 'amounts', 'answers', 'appeals', 'approaches', 'arches', 'assaults', 'associates', 'attacks', 'attempts', 'attributes', 'backs', 'bangs', 'banks', 'bargains', 'bars', 'bases', 'bats', 'beats', 'bellows', 'belts', 'bends', 'benefits', 'bites', 'blankets', 'blots', 'blows', 'blueprints', 'boards', 'bodies', 'borders', 'bores', 'bottles', 'bows', 'breaks', 'bridges', 'bristles', 'bubbles', 'bugs', 'bulletins', 'bullies', 'burns', 'butts', 'calls', 'caps', 'captures', 'cares', 'casts', 'catches', 'causes', 'censors', 'centers', 'challenges', 'champions', 'changes', 'charges', 'checks', 'claims', 'claps', 'clicks', 'clouds', 'clucks', 'clutches', 'colors', 'commands', 'comments', 'compounds', 'compresses', 'concentrates', 'concerns', 'conducts', 'conflicts', 'contacts', 'contracts', 'contrasts', 'controls', 'coordinates', 'costs', 'counts', 'courts', 'covers', 'cracks', 'credits', 'cries', 'crops', 'crosses', 'cuts', 'cycles', 'damages', 'dances', 'dashes', 'dates', 'deals', 'declines', 'decreases', 'decrees', 'deeds', 'delays', 'delights', 'demands', 'deserts', 'designs', 'desires', 'dictates', 'dies', 'dishes', 'dislikes', 'displays', 'dogs', 'doubles', 'drains', 'dreams', 'drifts', 'drinks', 'drives', 'drops', 'dwarfs', 'embraces', 'encounters', 'ends', 'equals', 'escapes', 'estimates', 'excuses', 'exercises', 'exhibits', 'experiences', 'extracts', 'faces', 'factors', 'falls', 'fans', 'fashions', 'favors', 'fears', 'features', 'feeds', 'fields', 'fights', 'figures', 'files', 'finishes', 'fishes', 'fits', 'flags', 'flares', 'flies', 'flourishes', 'flows', 'forces', 'forms', 'fractures', 'functions', 'gains', 'gestures', 'glories', 'graduates', 'guarantees', 'guides', 'handles', 'harbors', 'hates', 'hauls', 'haunts', 'heads', 'helps', 'hides', 'hinges', 'hints', 'hits', 'holds', 'honors', 'hopes', 'houses', 'howls', 'hunts', 'imports', 'increases', 'influences', 'initiates', 'interests', 'issues', 'jokes', 'jumps', 'keeps', 'kicks', 'kids', 'kills', 'kisses', 'knocks', 'knuckles', 'labels', 'labors', 'lags', 'lands', 'laps', 'lapses', 'laughs', 'lays', 'leads', 'leaps', 'leases', 'leaves', 'levels', 'lies', 'lifts', 'lights', 'likes', 'limits', 'lines', 'lists', 'lives', 'looks', 'looms', 'loves', 'makes', 'marches', 'markets', 'marks', 'matches', 'matters', 'means', 'measures', 'meets', 'mentions', 'merits', 'mirrors', 'misses', 'mistakes', 'moderates', 'mounts', 'moves', 'names', 'needs', 'notes', 'numbers', 'objects', 'offers', 'orders', 'outlines', 'paints', 'parades', 'parallels', 'passes', 'pauses', 'peers', 'permits', 'petitions', 'phones', 'photographs', 'picks', 'pictures', 'piles', 'places', 'plans', 'plays', 'plots', 'plunges', 'points', 'powers', 'practices', 'presents', 'preserves', 'presses', 'proceeds', 'projects', 'promises', 'protests', 'pulls', 'purchases', 'purges', 'pushes', 'quarrels', 'questions', 'rains', 'raises', 'rallies', 'ranches', 'ranges', 'ranks', 'rates', 'reaches', 'reasons', 'rebels', 'records', 'regards', 'registers', 'regrets', 'releases', 'remains', 'remarks', 'replies', 'reports', 'requests', 'reserves', 'respects', 'rests', 'results', 'returns', 'reviews', 'rides', 'rings', 'rises', 'rocks', 'rolls', 'rules', 'runs', 'rushes', 'sanctions', 'says', 'scales', 'scans', 'seals', 'searches', 'senses', 'services', 'sets', 'shakes', 'shapes', 'shares', 'sheds', 'shifts', 'shocks', 'shouts', 'shows', 'signals', 'signs', 'sketches', 'skins', 'skirts', 'slips', 'smells', 'smiles', 'snatches', 'sneers', 'snowballs', 'snows', 'solos', 'sounds', 'spans', 'sparks', 'speeds', 'spies', 'splashes', 'splits', 'sponsors', 'sports', 'spreads', 'springs', 'stains', 'stakes', 'stands', 'starts', 'states', 'stays', 'stems', 'steps', 'sticks', 'stops', 'stresses', 'stretches', 'strikes', 'struggles', 'studies', 'subjects', 'suits', 'sums', 'supplies', 'supports', 'surveys', 'switches', 'swoops', 'talks', 'tastes', 'terms', 'tests', 'thrusts', 'ties', 'times', 'tires', 'tops', 'tortures', 'totals', 'touches', 'towers', 'toys', 'traces', 'trades', 'trains', 'transfers', 'transports', 'traps', 'travels', 'treats', 'tries', 'trusts', 'turns', 'upsets', 'urges', 'uses', 'values', 'views', 'visits', 'votes', 'vows', 'walks', 'wants', 'watches', 'weights', 'winds', 'wins', 'wishes', 'wonders', 'works', 'worries', 'wrenches', 'yields']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Identify three-word prepositional phrases of the form IN + DET + NN (eg. in the lab)."
      ],
      "metadata": {
        "id": "1f_yobOSnEBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. What is the ratio of masculine to feminine pronouns?"
      ],
      "metadata": {
        "id": "VT86Y1OnnFEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fd = nltk.FreqDist(text)\n",
        "print((fd['he'] + fd['He']) / (fd['she'] + fd['She']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTKB5xSvpcM9",
        "outputId": "98ac8536-6b4c-4055-f094-0844c6916c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3384615384615386\n"
          ]
        }
      ]
    }
  ]
}