{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "HuWktKx9O9l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **7.1** The IOB format categorizes tagged tokens as I, O and B. Why are three tags necessary? What problem would be caused if we used I and O tags exclusively?"
      ],
      "metadata": {
        "id": "4Gg1YxgqKJUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 경계를 구분하는 태그가 없기 때문에 하나의 긴 청크와 두 개의 작은 청크를 구별하는 것이 불가능하다."
      ],
      "metadata": {
        "id": "nzKrzYuLMuLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.5** Write a tag pattern to cover noun phrases that contain gerunds, e.g. \"the/DT receiving/VBG end/NN\", \"assistant/NN managing/VBG editor/NN\". Add these patterns to the grammar, one per line. Test your work using some tagged sentences of your own devising."
      ],
      "metadata": {
        "id": "XXScpP8IKMj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "grammar = r\"\"\"NP: {}\"\"\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "sentences = [[(\"the\", \"DT\"), (\"receiving\", \"VBG\"), (\"end\", \"NN\")], \n",
        "             [(\"assistant\", \"NN\"),  (\"managing\", \"VBG\"),  (\"editor\", \"NN\")]]\n",
        "\n",
        "for sent in sentences:\n",
        "    print(cp.parse(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvI22a2eMZo5",
        "outputId": "1671ed7f-a8a9-4ee6-b48f-35a4737e3aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S the/DT receiving/VBG end/NN)\n",
            "(S assistant/NN managing/VBG editor/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [[(\"the\", \"DT\"), (\"playing\", \"VBG\"), (\"piano\", \"NN\")]]\n",
        "\n",
        "for sent in sentences:\n",
        "    print(cp.parse(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExwdkTxTMgvW",
        "outputId": "eadd2529-17ba-462a-b838-929fd3c84198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S the/DT playing/VBG piano/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the meaning of the performance metrics such as Accuracy, Precision, Recall, F-measure which are generated by \"accuracy\" function"
      ],
      "metadata": {
        "id": "tmZf4xftKWFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# performance metrics는 정확도, 재현율, 정밀도, F-score 등 모델의 성능을 평가하는 지표이다.\n",
        "# 어떤 데이터에 어떤 모델을 사용하느냐에 따라 정확도가 좋은 평가 지표일 수도, F-score가 좋은 지표일 수도 있다.\n",
        "# 성능 평가 지표를 보고 좋은 모델인지 아닌지 판단하는 데에 도움을 받을 수도 있고, 모델의 성능 개선을 할 때도 좋다."
      ],
      "metadata": {
        "id": "PGFUIliPMyDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Investigate what are the \"UnigramChunker\" and \"BigramChunker\". Why \"BigramChunker\" generates higher evaluation scores?"
      ],
      "metadata": {
        "id": "zOtF2twKKYnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UnigramChunker는 BigramChunker와 달리 단어의 순서를 전혀 고려하지 않기 때문이다."
      ],
      "metadata": {
        "id": "GLpnhn5VMylD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install svgling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeWUG65eYY3z",
        "outputId": "4a677e12-8d2c-4926-c713-084ef060057e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.3.1 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.3** Consider the sentence Kim arrived or Dana left and everyone cheered. Write down the parenthesized forms to show the relative scope of and and or. Generate tree structures corresponding to both of these interpretations."
      ],
      "metadata": {
        "id": "QRyh7-0-Kb6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Kim arrived) or (Dana left and everyone cheered).\n",
        "# (Kim arrived or Dana left) and everyone cheered.\n",
        "\n",
        "import nltk, re\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "S -> S Conj S\n",
        "VP -> \"arrived\" | \"left\" | \"cheered\"\n",
        "NP -> \"Kim\" | \"Dana\" | \"everyone\"\n",
        "Conj -> \"and\" | \"or\"\n",
        "\"\"\")\n",
        "\n",
        "sr_parse = nltk.ShiftReduceParser(grammar, trace=2)\n",
        "sent = 'Kim arrived or Dana left and everyone cheered'.split()\n",
        "for tree in sr_parse.parse(sent):\n",
        "    print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsHUsXUbLh0_",
        "outputId": "f05911e7-3d77-4059-ee20-038bca92b7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing 'Kim arrived or Dana left and everyone cheered'\n",
            "    [ * Kim arrived or Dana left and everyone cheered]\n",
            "  S [ 'Kim' * arrived or Dana left and everyone cheered]\n",
            "  R [ NP * arrived or Dana left and everyone cheered]\n",
            "  S [ NP 'arrived' * or Dana left and everyone cheered]\n",
            "  R [ NP VP * or Dana left and everyone cheered]\n",
            "  R [ S * or Dana left and everyone cheered]\n",
            "  S [ S 'or' * Dana left and everyone cheered]\n",
            "  R [ S Conj * Dana left and everyone cheered]\n",
            "  S [ S Conj 'Dana' * left and everyone cheered]\n",
            "  R [ S Conj NP * left and everyone cheered]\n",
            "  S [ S Conj NP 'left' * and everyone cheered]\n",
            "  R [ S Conj NP VP * and everyone cheered]\n",
            "  R [ S Conj S * and everyone cheered]\n",
            "  R [ S * and everyone cheered]\n",
            "  S [ S 'and' * everyone cheered]\n",
            "  R [ S Conj * everyone cheered]\n",
            "  S [ S Conj 'everyone' * cheered]\n",
            "  R [ S Conj NP * cheered]\n",
            "  S [ S Conj NP 'cheered' * ]\n",
            "  R [ S Conj NP VP * ]\n",
            "  R [ S Conj S * ]\n",
            "  R [ S * ]\n",
            "(S\n",
            "  (S (S (NP Kim) (VP arrived)) (Conj or) (S (NP Dana) (VP left)))\n",
            "  (Conj and)\n",
            "  (S (NP everyone) (VP cheered)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.5** In this exercise you will manually construct some parse trees.\n",
        "\n",
        "(a) Write code to produce two trees, one for each reading of the phrase old men and women"
      ],
      "metadata": {
        "id": "GSgidai0KkOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import Tree\n",
        "\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "\n",
        "S -> NP CC NP | JJ NP\n",
        "NP -> N | JJ N | N CC N\n",
        "N -> 'men' | 'women'\n",
        "JJ -> 'old'\n",
        "CC -> 'and'\n",
        "\"\"\")\n",
        "\n",
        "sent = ['old', 'men', 'and', 'women']\n",
        "parser = nltk.ChartParser(grammar)\n",
        "for tree in parser.parse(sent):\n",
        "    print(tree)\n",
        "\n",
        "trees = []\n",
        "for tree in parser.parse(sent):\n",
        "    trees.append(str(tree))\n",
        "\n",
        "for t in trees:\n",
        "    nltk.Tree.fromstring(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geuMtIFSNKrr",
        "outputId": "14375349-cc7b-4621-bb6e-54ffda3cb57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (JJ old) (NP (N men) (CC and) (N women)))\n",
            "(S (NP (JJ old) (N men)) (CC and) (NP (N women)))\n"
          ]
        }
      ]
    }
  ]
}